{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rossmann: XGBoost (Stage3 - Evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keggle Kernel: https://www.kaggle.com/paso84/xgboost-in-python-with-rmspe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input parameters**\n",
    "1. PROCESSED_TRAIN_CSV:The name of the file used to store the processed train data\n",
    "1. MODEL_PKL: The file containing the serialized model to evaluate\n",
    "1. MATRICS_OUT: The output file used to save calculate metrics\n",
    "\n",
    "**Output**\n",
    "1. A file that contains the calculated metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/shared/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = '../data'\n",
    "MODELS_DIR = '../models'\n",
    "METRICS_DIR = '../metrics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this cell is tagged `parameters`\n",
    "PROCESSED_TRAIN_CSV = DATASETS_DIR + '/processed/tst-train.csv'\n",
    "MODEL_PKL = MODELS_DIR + '/tst-model.pkl'\n",
    "METRICS_OUT = METRICS_DIR + '/tst.metrics'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se il notebook è eseguito su una macchina pulita installare i pacchetti necessari con i seguenti comandi ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl https://raw.githubusercontent.com/andrea-gioia/boostrap.ai/master/???\t | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se il notebook è eseguito all'interno di un ambiente virtuale conda con tutti i pacchetti specificati nel file di requirements già installati fare solo un check eseguendo i seguenti comandi ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dump environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.3\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                     /opt/conda\r\n",
      "custom                *  /opt/conda/envs/custom\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed value: \n",
    "seed_value= 42  \n",
    "\n",
    "\n",
    "# Set `python` built-in pseudo-random generator at a fixed value: \n",
    "random.seed(seed_value) \n",
    "\n",
    "# Set `numpy` pseudo-random generator at a fixed value:\n",
    "np.random.seed(seed_value) \n",
    "\n",
    "# Set `torch` pseudo-random generator at a fixed value:\n",
    "torch.manual_seed(seed_value)\n",
    "torch.backends.cudnn.deterministic = True \n",
    "torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define shared functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToWeight(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "\n",
    "def rmspe(yhat, y):\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n",
    "    return rmspe\n",
    "\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    y = y.get_label()\n",
    "    y = np.exp(y) - 1\n",
    "    yhat = np.exp(yhat) - 1\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n",
    "    return \"rmspe\", rmspe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input data frame ../data/processed/tst-train.csv size is (1017209, 37)\n",
      "\n",
      "Train set size: 762906; Validation set size: 254303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_processed_train = pd.read_csv(PROCESSED_TRAIN_CSV)\n",
    "print('The input data frame {} size is {}\\n'.format(PROCESSED_TRAIN_CSV, df_processed_train.shape))\n",
    "\n",
    "df_processed_train = df_processed_train.loc[:, df_processed_train.columns != 'Date']\n",
    "df_train, df_valid = model_selection.train_test_split(df_processed_train, test_size=.25, shuffle=False)\n",
    "print('Train set size: {}; Validation set size: {}\\n'.format(df_train.shape[0], df_valid.shape[0]))\n",
    "\n",
    "\n",
    "#features = ['Store', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'SchoolHoliday', 'DayOfWeek', 'month', 'day', 'year', 'StoreType', 'Assortment']\n",
    "#X_train = df_train[fetaures];\n",
    "X_train = df_train.loc[:, df_train.columns != 'Sales']\n",
    "y_train = np.log(df_train[\"Sales\"] + 1) # perchè?\n",
    "\n",
    "#X_valid = df_valid[features]\n",
    "X_valid = df_valid.loc[:, df_valid.columns != 'Sales']\n",
    "y_valid = np.log(df_valid[\"Sales\"] + 1) # perchè?\n",
    "\n",
    "\n",
    "dm_train = xgb.DMatrix(X_train, y_train)\n",
    "dm_valid = xgb.DMatrix(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = pickle.load(open(MODEL_PKL, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(m, lossfunct=rmspe):\n",
    "    lf_train = lossfunct(np.exp(m.predict(xgb.DMatrix(X_train)))-1, np.exp(y_train)-1)\n",
    "    lf_valid = lossfunct(np.exp(m.predict(xgb.DMatrix(X_valid)))-1, np.exp(y_valid)-1)\n",
    "    res = [lf_train, lf_valid]\n",
    "    #if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04493089660236272, 0.1444584758207349]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = calculate_metrics(gbm)\n",
    "metrics #[0.04457844963361768, 0.06381738749662394]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(METRICS_OUT, 'w') as fd:\n",
    "    fd.write('rmspe(train): {}\\n'.format(metrics[0]))\n",
    "    fd.write('rmspe(valid): {}\\n'.format(metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../metrics/tst.metrics'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METRICS_OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmspe(train): 0.04493089660236272\r\n",
      "rmspe(valid): 0.1444584758207349\r\n"
     ]
    }
   ],
   "source": [
    "!cat {METRICS_OUT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
