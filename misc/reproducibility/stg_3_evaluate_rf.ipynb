{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rossmann: Random forest (Stage3 - Evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keggle Kernel: https://www.kaggle.com/paso84/xgboost-in-python-with-rmspe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input parameters**\n",
    "1. PROCESSED_TRAIN_CSV:The name of the file used to store the processed train data\n",
    "1. MODEL_PKL: The file containing the serialized model to evaluate\n",
    "1. MATRICS_OUT: The output file used to save calculate metrics\n",
    "\n",
    "**Output**\n",
    "1. A file that contains the calculated metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/shared/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = '../data'\n",
    "MODELS_DIR = '../models'\n",
    "METRICS_DIR = '../metrics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this cell is tagged `parameters`\n",
    "PROCESSED_TRAIN_CSV = DATASETS_DIR + '/processed/tst-train.csv'\n",
    "MODEL_PKL = MODELS_DIR + '/tst-model.pkl'\n",
    "METRICS_OUT = METRICS_DIR + '/tst.metrics'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se il notebook è eseguito su una macchina pulita installare i pacchetti necessari con i seguenti comandi ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl https://raw.githubusercontent.com/andrea-gioia/boostrap.ai/master/???\t | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se il notebook è eseguito all'interno di un ambiente virtuale conda con tutti i pacchetti specificati nel file di requirements già installati fare solo un check eseguendo i seguenti comandi ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dump environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.4\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                     /opt/conda\r\n",
      "custom                *  /opt/conda/envs/custom\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed value: \n",
    "seed_value= 42  \n",
    "\n",
    "\n",
    "# Set `python` built-in pseudo-random generator at a fixed value: \n",
    "random.seed(seed_value) \n",
    "\n",
    "# Set `numpy` pseudo-random generator at a fixed value:\n",
    "np.random.seed(seed_value) \n",
    "\n",
    "# Set `torch` pseudo-random generator at a fixed value:\n",
    "torch.manual_seed(seed_value)\n",
    "torch.backends.cudnn.deterministic = True \n",
    "torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define shared functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(p,a): return np.sqrt(((a-p)**2).mean())\n",
    "\n",
    "# ritorna un vettore w in cui w_i = y_i^-2 se i!=0, 0 altrimnti\n",
    "# serve per ignorare dalla misura finale i casi in cui la variabile y da predirre e nulla\n",
    "def toWeight(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "\n",
    "def rmspe(p, a):\n",
    "    w = toWeight(a)\n",
    "    rmspe = np.sqrt(np.mean( w * (a - p)**2 ))\n",
    "    return rmspe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input data frame ../data/processed/tst-train.csv size is (1017209, 37)\n",
      "\n",
      "Train set size: 762906; Validation set size: 254303\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762906, 35), (762906,), (254303, 35), (254303,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed_train = pd.read_csv(PROCESSED_TRAIN_CSV)\n",
    "print('The input data frame {} size is {}\\n'.format(PROCESSED_TRAIN_CSV, df_processed_train.shape))\n",
    "\n",
    "df_processed_train = df_processed_train.loc[:, df_processed_train.columns != 'Date']\n",
    "df_train, df_valid = model_selection.train_test_split(df_processed_train, test_size=.25, shuffle=False)\n",
    "print('Train set size: {}; Validation set size: {}\\n'.format(df_train.shape[0], df_valid.shape[0]))\n",
    "\n",
    "X_train = df_train.loc[:, df_train.columns != 'Sales']\n",
    "y_train = df_train['Sales']\n",
    "\n",
    "X_valid = df_valid.loc[:, df_valid.columns != 'Sales']\n",
    "y_valid = df_valid['Sales']\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm = pickle.load(open(MODEL_PKL, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(m, lossfunct=rmse):\n",
    "    lf_train = lossfunct(m.predict(X_train), y_train)\n",
    "    lf_valid = lossfunct(m.predict(X_valid), y_valid)\n",
    "    r2_train = m.score(X_train, y_train)\n",
    "    r2_valid = m.score(X_valid, y_valid)\n",
    "    res = [lf_train, lf_valid,  \n",
    "           r2_train, r2_valid]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02639480588395337,\n",
       " 0.06847645742979377,\n",
       " 0.9974198433116129,\n",
       " 0.9797561541455969]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = calculate_metrics(rfm, lossfunct=rmspe)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(METRICS_OUT, 'w') as fd:\n",
    "    fd.write('rmspe(train): {}\\n'.format(metrics[0]))\n",
    "    fd.write('rmspe(valid): {}\\n'.format(metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../metrics/tst.metrics'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METRICS_OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmspe(train): 0.02639480588395337\r\n",
      "rmspe(valid): 0.06847645742979377\r\n"
     ]
    }
   ],
   "source": [
    "!cat {METRICS_OUT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
